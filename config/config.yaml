<<<<<<< HEAD
# Config file for the NYU-NEI Retinotopy Dataset.
=======
################################################################################
# This file contains the configuration for the cortex-annotate toolkit. By
# editing this file, one can configure cortex-annotate to work with various
# datasets and to enable annotation of specific contours, points, and
# boundaries. The current contents of this file configure the tool for
# annotation of the visual cortex of subjects in the NYU retinotopy dataset.

>>>>>>> 160aeb4285bc6380d3af5687f1dc8d53a514d3d6

display:
  figsize: [4, 4]
  dpi: 128
  plot_options:
    color: [0.25, 0.25, 0.75]
    linewidth: 1
    markersize: 1
    linestyle: "solid"
  fg_options:
    color: [0.55, 0.55, 0.9]
    markersize: 2

init: |
<<<<<<< HEAD
    # Import libraries.
    import neuropythy as ny, numpy as np
    from pathlib import Path
    # Declare where the dataset lives (inside the running docker container):
    data_path = Path('/data/derivatives')
    # This is the neuropythy mask of the occipital pole for making flatmaps.
    occpole_mask = ('parcellation', 43)
=======
  # Several code-blocks in this config.yaml file use the numpy and neuropythy
  # libraries, so we load them here.
  import numpy as np
  import neuropythy as ny
  # We also want to create an object that tracks the S3 path/data for the NSD.
  # We use the cache path '/cache/nsd' because the /cache directory is always
  # abailable for use with cache files inside of the docker container that runs
  # the annotation tool.
  nsd_path = ny.util.pseudo_path(
      's3://natural-scenes-dataset/nsddata/',
      cache_path='/cache/nsd')
  # We will specifically load these population receptive fields (pRF) files in
  # order to draw visual area annotations on the retinotopic maps for each
  # subject.
  nsd_prf_files = {
      "polar_angle": "prfangle.mgz",
      "eccentricity": "prfeccentricity.mgz",
      "cod": "prfR2.mgz",
      "wang15": "Kastner2015.mgz"}
  # This occipital pole mask is used with neuropythy's flatmap code; the tuple
  # indicates that the FreeSurfer parcellation property uses the value 43 to
  # indicate the occipital pole of the brain.
  occpole_mask = ('parcellation', 43)
>>>>>>> 160aeb4285bc6380d3af5687f1dc8d53a514d3d6

# We assume in this example that the libraries neuropythy and numpy have been
# imported (as ny and np respectively) in the init section (see below).
targets:
<<<<<<< HEAD
    # The Subject ID is selectable because there are 3 of them.
    Subject ID:
       - sub-wlsubj119
       - sub-wlsubj127
       - sub-wlsubj136
       - sub-wlsubj137
       - sub-wlsubj143
       - sub-wlsubj144
       - sub-wlsubj145
       - sub-wlsubj146
       - sub-wlsubj147
       - sub-wlsubj148
       - sub-wlsubj149
       - sub-wlsubj150
       - sub-wlsubj151
       - sub-wlsubj152
       - sub-wlsubj153
       - sub-wlsubj154
       - sub-wlsubj155
       - sub-wlsubj156
       - sub-wlsubj157
       - sub-wlsubj158
       - sub-wlsubj159
       - sub-wlsubj160
       - sub-wlsubj162
       - sub-wlsubj163
       - sub-wlsubj164
       - sub-wlsubj165
       - sub-wlsubj166
       - sub-wlsubj167
       - sub-wlsubj168
       - sub-wlsubj169
       - sub-wlsubj170
       - sub-wlsubj171
       - sub-wlsubj172
       - sub-wlsubj173
       - sub-wlsubj174
       - sub-wlsubj175
       - sub-wlsubj176
    # Once we have established the subject ID, we can load the subject object,
    # which we will need for generating images.
    # This code block assumes that the `init` section defined the
    # `data_src` variable.
    subject: |
        subj = target['Subject ID']
        path = data_path / 'freesurfer' / subj
        return ny.freesurfer_subject(str(path))
    # The hemisphere is another selectable item because there are 2 of them.
    Hemisphere:
        - LH
        - RH
    # Cortex, which has a string, is again a lazy value defined by a code
    # snippet. This snippet extracts the Cortex object for the selected
    # hemisphere.
    cortex: |
        subj = target['Subject ID']
        h = target['Hemisphere'].lower()
        ctx = target['subject'].hemis[h]
        # Load the retinotopy also.
        path = data_path / 'prfvista' / subj / 'ses-nyu3t01'
        props = dict(
            polar_angle = ny.load(str(path / f"{h}.angle_adj.mgz")),
            theta = ny.load(str(path / f"{h}.angle.mgz")),
            eccentricity = ny.load(str(path / f"{h}.eccen.mgz")),
            x = ny.load(str(path / f"{h}.x.mgz")),
            y = ny.load(str(path / f"{h}.y.mgz")),
            radius = ny.load(str(path / f"{h}.sigma.mgz")),
            cod = ny.load(str(path / f"{h}.vexpl.mgz")))
        return ctx.with_prop(props)
    # Additionally, we create a flatmap projection for the hemisphere. Here we
    # make a projection of the occipital cortex.
    flatmap: |
        # Start by importing neuropythy.
        # Make a flatmap projection of the occipital cortex.
        c = target['cortex']
        return c.mask_flatmap(occpole_mask,
                              map_right='right',
                              radius=np.pi/2,
                              registration='native')
    # Finally, it's useful to have information about the image coordinates in
    # the target data, so we add these.
    xlim: |
        x = target['flatmap'].coordinates[0]
        return (np.min(x), np.max(x))
    ylim: |
        y = target['flatmap'].coordinates[1]
        return (np.min(y), np.max(y))
    projection_data: |
      proj = target['flatmap'].meta_data['projection']
      proj = proj.copy(mesh=None)
      return proj.normalize()
      
# When annotating V1-V3 using retinotopic maps; we need contours for the
# periphery and for V1, V2, and V3 boundaries. When drawn like this, they are
# all simple contours (not boundaries).
=======
  # The NSD contains 8 subjects, listed below. The 'Subject ID' entry will be
  # a dropdown menu in the annotation tool because it is a list of multiple
  # choices rather than a code-block or a list with a single entry.
  Subject ID:
    - subj01
    - subj02
    - subj03
    - subj04
    - subj05
    - subj06
    - subj07
    - subj08
  # The 'subject' entry is a multi-line string, so it is interpreted as a Python
  # code snippet. This snippet is compiled into a function whose parameter list
  # contains only the variable `target`. The `target` will be a dictionary with
  # the target data above the subject, so in this case only the 'Subject ID'.
  subject: |
    # Get the subject ID that the user chose from the above selection list.
    sid = target['Subject ID']
    # Find a sub-path for the subject's FreeSurfer directory; we get the
    # nsd_path variable from the `init` section of the config.yaml file; see
    # above.
    fs_path = nsd_path.subpath('freesurfer', sid)
    # Load and return a FreeSurfer subject object for this path.
    return ny.freesurfer_subject(fs_path)
  # The 'Hemisphere' is a choice for the user; as a list of two options, it will
  # appear as a dropdown meny with these two options in the annotation tool.
  Hemisphere:
    - LH
    - RH
  # We will want to include the Wang et al. (2015) probabilistic visual area
  # atlas as an optional annotation that users can turn on and off (see the
  # `builtin_annotations` section, below). This element of the target section
  # loads the Wang atlas and applies it to the subject we are workign with.
  wang15: |
    import neuropythy.commands as nycmd, os
    # Grab the subject object that was loaded in the 'subject' section.
    sub = target['subject']
    # We also need to know the hemisphere name.
    h = target['Hemisphere'].lower()
    # Get the subject's cache-path; this is tracked by neuropythy.
    subpath = sub.pseudo_path.cache_path
    # Possibly, this atlas has already been applied to this subject; if so, we
    # don't need to (re-)run neuropythy's atlas command (which applies the atlas
    # to the subject and saves it as a file).
    wangpath = os.path.join(subpath, 'surf', f'{h}.wang15_mplbl.mgz')
    if not os.path.isfile(wangpath):
        # Make sure the fsaverage-alignment has already been loaded into cache;
        # because the atlas command operates on the filesystem while the subject
        # and cache path load things lazily, we need to make sure these have
        # already been downloaded before we run the command.
        sub.hemis['lh'].surface('fsaverage')
        sub.hemis['rh'].surface('fsaverage')
        # Now run the atlas command.
        nycmd.atlas.main(["-awang15", "-fmgz", subpath])
    # Load and return the file.
    return ny.load(wangpath)
  # The 'cortex' key in the target data is for the cortical surface object,
  # which is managed and loaded by neuropythy from the subject's FreeSurfer
  # object. Note that the 'cortex' entry is like the 'subject' entry in that it
  # is compiled into a function whose only parameter is a dict object called
  # `target`, but because it is farther down in the target section, the `target`
  # parameter will contain entries for 'Subject ID', 'subject', and 'Hemisphere'
  # from the sections above.
  cortex: |
    # Extract the subject object and the hsmisphere name.
    sid = target['Subject ID']
    sub = target['subject']
    h = target['Hemisphere'].lower()
    # Load retinotopic mapping data from the label directory, where these data
    # are stored on the NSD repository.
    label_path = nsd_path.subpath('freesurfer', sid, 'label')
    props = {
        k: ny.load(label_path.subpath(f'{h}.{filename}'))
        for (k,filename) in nsd_prf_files.items()}
    # Convert the polar angle into Neuropythy's "visual" format (i.e., 0 degrees
    # is the upper vertical meridian, 90 degrees is the right horizontal
    # meridian, and -90 degrees is the left horizontal meridian.
    ang = props['polar_angle']
    props['polar_angle'] = np.mod(90 - ang + 180, 360) - 180
    # Add the Wang et al. (2015) atlas, loaded in the above 'wang15' section.
    props['wang15'] = target['wang15']
    # Grab the appropriate coretx/hemisphere object.
    cortex = sub.hemis[h]
    # Finally, return that hemisphere object with the properties associated with
    # it (this is Neuropythy's typical modus operandi for adding properties to
    # existing objects: make a copy with the properties attached).
    return cortex.with_prop(props)
  # Finally, we include a 'flatmap' entry of the `targets` section in order to
  # create a flattened projection of the hemisphere for annotation. We use the
  # `mask_flatmap` method of the cortex/hemisphere object in order to create a
  # projection of the inflated native surface that is centered on the occipital
  # pole. This uses the `occpole_mask` defined in the `init` section above.
  flatmap: |
    cortex = target['cortex']
    return cortex.mask_flatmap(occpole_mask, map_right='right', radius=np.pi/2)

>>>>>>> 160aeb4285bc6380d3af5687f1dc8d53a514d3d6
annotations:
  # V1 contours:
  V1 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V1 UVM (ventral):
    fixed_head: V1 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V1 LVM (dorsal):
    fixed_head: V1 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V1 Periphery:
    fixed_head:
      requires: V1 UVM (ventral)
      calculate: |
        return annotations['V1 UVM (ventral)'][-1,:]
    fixed_tail:
      requires: V1 LVM (dorsal)
      calculate: |
        return annotations['V1 LVM (dorsal)'][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  # V2 contours:
  V2 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V2 UVM (ventral):
    fixed_head: V2 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V2 LVM (dorsal):
    fixed_head: V2 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V2 Ventral Periphery:
    fixed_head:
      requires: V2 UVM (ventral)
      calculate: |
        return annotations['V2 UVM (ventral)'][-1,:]
    fixed_tail:
      requires: V1 UVM (ventral)
      calculate: |
        return annotations['V1 UVM (ventral)'][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V2 Dorsal Periphery:
    fixed_head:
      requires: V2 LVM (dorsal)
      calculate: |
        return annotations['V2 LVM (dorsal)'][-1,:]
    fixed_tail:
      requires: V1 LVM (dorsal)
      calculate: |
        return annotations['V1 LVM (dorsal)'][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  # V3 contours:
  V3 Foveal Point:
    type: point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V3 UVM (ventral):
    fixed_head: V3 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V3 LVM (dorsal):
    fixed_head: V3 Foveal Point
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V3 Ventral Periphery:
    fixed_head:
      requires: V3 UVM (ventral)
      calculate: |
        return annotations['V3 UVM (ventral)'][-1,:]
    fixed_tail:
      requires: V2 UVM (ventral)
      calculate: |
        return annotations['V2 UVM (ventral)'][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]
  V3 Dorsal Periphery:
    fixed_head:
      requires: V3 LVM (dorsal)
      calculate: |
        return annotations['V3 LVM (dorsal)'][-1,:]
    fixed_tail:
      requires: V2 LVM (dorsal)
      calculate: |
        return annotations['V2 LVM (dorsal)'][-1,:]
    grid:
      - ["polar_angle", "eccentricity"]
      - ["curvature", "cod"]

builtin_annotations:
  Wang2015 Atlas:
    type: points
    plot_options:
      color: [1, 1, 0]
      markersize: 1
      visible: false
    data: |
      fmap = target['flatmap']
      (u,v) = fmap.tess.indexed_edges
      w = fmap.prop('wang15')
      xy = fmap.coordinates
      ii = w[u] != w[v]
      dat = np.mean([xy[:,u[ii]], xy[:,v[ii]]], axis=0)
      return [dat.T]

figures:
  term: |
    xy = target['flatmap'].coordinates
    (xmin,ymin) = np.min(xy, axis=1)
    (xmax,ymax) = np.max(xy, axis=1)
    axes.set_xlim((xmin,xmax))
    axes.set_ylim((ymin,ymax))
  polar_angle: |
    ny.cortex_plot(target['flatmap'], color="polar_angle", axes=axes)
  eccentricity: |
    ny.cortex_plot(target['flatmap'], color="eccentricity", axes=axes)
  cod: |
    ny.cortex_plot(target['flatmap'], color="cod", axes=axes,
                   cmap='hot', vmin=0, vmax=100)
  curvature: |
    ny.cortex_plot(target['flatmap'], axes=axes)

review: |
  #from annotate import watershed_contours
  #im = watershed_contours(annotations.values(), max_depth=1)
  #axes.imshow(im, cmap='hsv', vmin=0, vmax=1.5*np.max(im))
  import numpy as np
  # V1:
  v1uvm = annotations['V1 UVM (ventral)']
  v1lvm = annotations['V1 LVM (dorsal)']
  v1per = annotations['V1 Periphery']
  v1pol = np.vstack([v1uvm, v1per, np.flipud(v1lvm)])
  # V2:
  v2uvm = annotations['V2 UVM (ventral)']
  v2lvm = annotations['V2 LVM (dorsal)']
  v2pev = annotations['V2 Ventral Periphery']
  v2ped = annotations['V2 Dorsal Periphery']
  v2pol = np.vstack(
      [v2uvm, v2pev, np.flipud(v1uvm), v1lvm, np.flipud(v2ped), np.flipud(v2lvm)])
  # V3:
  v3uvm = annotations['V3 UVM (ventral)']
  v3lvm = annotations['V3 LVM (dorsal)']
  v3pev = annotations['V3 Ventral Periphery']
  v3ped = annotations['V3 Dorsal Periphery']
  v3pol = np.vstack(
      [v3uvm, v3pev, np.flipud(v2uvm), v2lvm, np.flipud(v3ped), np.flipud(v3lvm)])
  # Turn these into traces:
  fmap = target['flatmap']
  v1_trace = ny.path_trace(fmap, v1pol.T, closed=True)
  v2_trace = ny.path_trace(fmap, v2pol.T, closed=True)
  v3_trace = ny.path_trace(fmap, v3pol.T, closed=True)
  # Convert the path traces into paths then into labels:
  cortex = target['cortex']
  v1_path = v1_trace.to_path(cortex)
  v2_path = v2_trace.to_path(cortex)
  v3_path = v3_trace.to_path(cortex)
  v1 = v1_path.label > 0.5
  v2 = v2_path.label > 0.5
  v3 = v3_path.label > 0.5
  if np.sum(v1) > np.sum(~v1):
    v1 = ~v1
  if np.sum(v2) > np.sum(~v2):
    v2 = ~v2
  if np.sum(v3) > np.sum(~v3):
    v3 = ~v3
  labels = np.zeros(cortex.vertex_count, dtype=int)
  labels[v1] = 1
  labels[v2] = 2
  labels[v3] = 3
  fmap_labels = labels[fmap.labels]
  # If the user saves the contours, we want to save these labels.
  save_hooks['v123-labels.mgz'] = lambda filename: ny.save(filename, labels)
  # Plot the results:
  ny.cortex_plot(
      fmap,
      color=fmap_labels,
      cmap='rainbow',
      mask=(fmap_labels > 0),
      axes=axes,
      alpha=0.5)
  axes.axis('equal')
  axes.axis('off')

